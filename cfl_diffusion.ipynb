{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a738740-6548-45ea-a7fd-a7aa40e1d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import linalg, stats\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import mixture, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "                    \n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "from torchcam.methods import GradCAM, GradCAMpp\n",
    "from torchcam.utils import overlay_mask\n",
    "import torch.optim as optim\n",
    "from torch.nn import DataParallel\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "# plt.rcParams['figure.dpi'] = 300\n",
    "device = torch.device('cuda:0')\n",
    "# warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7321b68-3cb5-42c1-8974-f88ade1cf946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 9912422/9912422 [00:00<00:00, 45882418.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 28881/28881 [00:00<00:00, 67863133.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 1648877/1648877 [00:00<00:00, 36899120.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 4542/4542 [00:00<00:00, 20178.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Client train labels (for a time slice of Client 0): tensor([0, 1])\n",
      "Client train samples (for a time slice of Client 0): 500\n",
      "Client test labels: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Client test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "def non_iid_mnist_split_pytorch(num_clients=20, samples_per_label=250, original_clients=100):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    train_loader = DataLoader(mnist_train, batch_size=len(mnist_train), shuffle=True)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=len(mnist_test), shuffle=False)\n",
    "    x_train, y_train = next(iter(train_loader)); x_test, y_test = next(iter(test_loader))\n",
    "\n",
    "    idx_label = {i: [] for i in range(10)}\n",
    "    for idx, label in enumerate(y_train):\n",
    "        idx_label[label.item()].append(idx)\n",
    "\n",
    "    client_data_train = {i: [] for i in range(num_clients)}\n",
    "    for i in range(original_clients):\n",
    "        chosen_labels = [(i*2)%10, (i*2+1)%10]\n",
    "        chosen_indices = []\n",
    "        for label in chosen_labels:\n",
    "            if len(idx_label[label]) < samples_per_label:\n",
    "                idx_label[label] = list(torch.where(y_train == label)[0].cpu().numpy())\n",
    "            label_indices = idx_label[label][:samples_per_label]\n",
    "            chosen_indices.extend(label_indices)\n",
    "            idx_label[label] = idx_label[label][samples_per_label:]\n",
    "        client_indices_tensor = torch.tensor(chosen_indices, dtype=torch.long)\n",
    "        client_id = i // (original_clients // num_clients)\n",
    "        if not client_data_train[client_id]:\n",
    "            for _ in range(5):\n",
    "                client_data_train[client_id].append(([], []))\n",
    "        client_data_train[client_id][i % 5][0].append(x_train[client_indices_tensor])\n",
    "        client_data_train[client_id][i % 5][1].append(y_train[client_indices_tensor])\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        for time_id in range(5):\n",
    "            client_data_train[client_id][time_id] = (\n",
    "                torch.cat(client_data_train[client_id][time_id][0], dim=0),\n",
    "                torch.cat(client_data_train[client_id][time_id][1], dim=0))\n",
    "\n",
    "    client_data_test = (x_test, y_test)\n",
    "    return client_data_train, client_data_test\n",
    "\n",
    "client_data_train, client_data_test = non_iid_mnist_split_pytorch()\n",
    "print(\"Client train labels (for a time slice of Client 0):\", torch.unique(client_data_train[0][0][1]))\n",
    "print(\"Client train samples (for a time slice of Client 0):\", len(client_data_train[0][0][1]))\n",
    "print(\"Client test labels:\", torch.unique(client_data_test[1]))\n",
    "print(\"Client test samples:\", len(client_data_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1a70d3d-e986-4de9-adaa-d5a78720e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "from labml_nn.diffusion.ddpm.utils import gather\n",
    "from labml_nn.diffusion.ddpm.unet import UNet\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "class DenoiseDiffusion:\n",
    "    def __init__(self, eps_model: nn.Module, n_steps: int, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.eps_model = eps_model\n",
    "        self.beta = torch.linspace(0.0001, 0.02, n_steps).to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "        self.n_steps = n_steps\n",
    "        self.sigma2 = self.beta\n",
    "\n",
    "    def q_xt_x0(self, x0: torch.Tensor, t: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        mean = gather(self.alpha_bar, t) ** 0.5 * x0\n",
    "        var = 1 - gather(self.alpha_bar, t)\n",
    "        return mean, var\n",
    "\n",
    "    def q_sample(self, x0: torch.Tensor, t: torch.Tensor, eps: Optional[torch.Tensor] = None):\n",
    "        if eps is None:\n",
    "            eps = torch.randn_like(x0)\n",
    "        mean, var = self.q_xt_x0(x0, t)\n",
    "        return mean + (var ** 0.5) * eps\n",
    "\n",
    "    def p_sample(self, xt: torch.Tensor, t: torch.Tensor):\n",
    "        eps_theta = self.eps_model(xt, t)\n",
    "        alpha_bar = gather(self.alpha_bar, t)\n",
    "        alpha = gather(self.alpha, t)\n",
    "        eps_coef = (1 - alpha) / (1 - alpha_bar) ** .5\n",
    "        mean = 1 / (alpha ** 0.5) * (xt - eps_coef * eps_theta)\n",
    "        var = gather(self.sigma2, t)\n",
    "        eps = torch.randn(xt.shape, device=device)\n",
    "        return mean + (var ** .5) * eps\n",
    "\n",
    "    def loss(self, x0: torch.Tensor, noise: Optional[torch.Tensor] = None):\n",
    "        batch_size = x0.shape[0]\n",
    "        t = torch.randint(0, self.n_steps, (batch_size,), device=device, dtype=torch.long)\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "        xt = self.q_sample(x0, t, eps=noise)\n",
    "        eps_theta = self.eps_model(xt, t)\n",
    "        return F.mse_loss(noise, eps_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ec55c14-4fa5-4874-87f4-e4c0b5a6db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights(weights_list):\n",
    "    avg_weights = {}\n",
    "    for key in weights_list[0].keys():\n",
    "        if weights_list[0][key].dtype != torch.long:\n",
    "            avg_weights[key] = torch.mean(torch.stack([weights[key] for weights in weights_list]), dim=0)\n",
    "    return avg_weights\n",
    "    \n",
    "def train_client(client_data, global_model, criterion, local_epochs):\n",
    "    client_model = CNN().to(device)\n",
    "    client_model.load_state_dict(copy.deepcopy(global_model).state_dict())\n",
    "    optimizer = optim.SGD(client_model.parameters(), lr=0.001)\n",
    "    data, target = client_data\n",
    "    data = data.float().to(device); target = target.long().to(device)\n",
    "    data_loader = torch.utils.data.DataLoader(list(zip(data, target)), batch_size=32, shuffle=True)\n",
    "    for epoch in range(local_epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_data, batch_target in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(batch_data)\n",
    "            loss = criterion(output, batch_target)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(batch_target.view_as(pred)).sum().item()\n",
    "            total += batch_target.size(0)\n",
    "        \n",
    "        accuracy = 100. * correct / total\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "    return client_model, avg_loss, accuracy\n",
    "\n",
    "def test_client(client_data, global_model):\n",
    "    global_model = global_model.to(device)\n",
    "    data, target = client_data\n",
    "    data = data.float().to(device); target = target.long().to(device)\n",
    "    with torch.no_grad():\n",
    "        output = global_model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / target.size(0)\n",
    "    return accuracy\n",
    "\n",
    "def FedAvg(global_model, client_data_train, client_data_test, iterations=100, epoch=5):\n",
    "    criterion = nn.NLLLoss()\n",
    "    accuracy_matrix = []\n",
    "    for ite in range(iterations):\n",
    "        client_models = []\n",
    "        data_slice = (ite // 20) % 5 \n",
    "        for client in client_data_train:\n",
    "            current_client_data = client_data_train[client][data_slice]\n",
    "            client_model, avg_loss, accuracy = train_client(current_client_data, global_model, criterion, epoch)\n",
    "            client_models.append(client_model.state_dict())\n",
    "            # print(f\"Iteration: {ite} - Client {client} - Data Slice: {data_slice} - Train Loss: {avg_loss:.4f}, Train Acc: {accuracy:.2f}%\")\n",
    "\n",
    "        global_weights = average_weights(client_models)\n",
    "        global_model.load_state_dict(global_weights)\n",
    "        test_accuracy = test_client(client_data_test, global_model)\n",
    "        accuracy_matrix.append(test_accuracy)\n",
    "        print(f\"Iteration: {ite} - Test Acc: {test_accuracy:.2f}%\")\n",
    "    return accuracy_matrix\n",
    "\n",
    "def train_diffusion_model(diffusion_model, client_data, epochs=200):\n",
    "    data, target = client_data\n",
    "    data = data.float().to(device); target = target.long().to(device)\n",
    "    data_loader = torch.utils.data.DataLoader(list(zip(data, target)), batch_size=32, shuffle=True)\n",
    "    optimizer = optim.Adam(diffusion_model.eps_model.parameters(), lr=0.0001)\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch, _ in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = diffusion_model.loss(x_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(epoch, loss.item())\n",
    "    return diffusion_model\n",
    "            \n",
    "def generate_synthetic_data(diffusion_model, amount):\n",
    "    image_shape = (1, 32, 32)\n",
    "    synthetic_data = torch.randn((amount, *image_shape), device=device)\n",
    "    with torch.no_grad():\n",
    "        for t_ in reversed(range(diffusion_model.n_steps)):\n",
    "            t = diffusion_model.n_steps - t_ - 1\n",
    "            t_tensor = synthetic_data.new_full((amount,), t, dtype=torch.long)\n",
    "            synthetic_data = diffusion_model.p_sample(synthetic_data, t_tensor)\n",
    "    return synthetic_data\n",
    "\n",
    "def combine_data(real_data, synthetic_data, synthetic_label):\n",
    "    real_x, real_y = real_data\n",
    "    real_x = real_x.float().to(device); real_y = real_y.long().to(device)\n",
    "    # synthetic_y = torch.zeros(synthetic_data.size(0), dtype=torch.long, device=device)\n",
    "    combined_x = torch.cat([real_x, synthetic_data], dim=0)\n",
    "    # combined_y = torch.cat([real_y, synthetic_y], dim=0)\n",
    "    combined_y = torch.cat([real_y, synthetic_label], dim=0)\n",
    "    return combined_x, combined_y\n",
    "\n",
    "def FedAvg_with_Diffusion(global_model, client_data_train, client_data_test, diffusion_models, iterations=100, epoch=5):\n",
    "    criterion = nn.NLLLoss()\n",
    "    accuracy_matrix = []\n",
    "    \n",
    "    for ite in range(iterations):\n",
    "        if ite % 20 == 19:\n",
    "            for client in client_data_train:\n",
    "                diffusion_models[client] = train_diffusion_model(copy.deepcopy(diffusion_models[client]), client_data_train[client][(ite // 20) % 5])\n",
    "                synthetic_data = generate_synthetic_data(diffusion_models[client], amount=100) # why?                \n",
    "                torch.save(synthetic_data, 'synthetic_data.pt')\n",
    "                stophere # why?\n",
    "\n",
    "        if ite % 20 == 0:\n",
    "            combined_client_data = {} \n",
    "            for client in client_data_train:\n",
    "                current_client_data = client_data_train[client][(ite // 20) % 5]\n",
    "                if ite >= 20:                    \n",
    "                    synthetic_data = generate_synthetic_data(diffusion_models[client], amount=len(current_client_data[0]))\n",
    "                    # TODO: use the current classifier to label the synthetic data, check dim\n",
    "                    client_model_syn = CNN()\n",
    "                    client_model_syn.load_state_dict(client_models[client])\n",
    "                    synthetic_label = client_model_syn(synthetic_data)\n",
    "                    combined_client_data[client] = combine_data(current_client_data, synthetic_data, synthetic_label)\n",
    "                    # combined_client_data[client] = combine_data(current_client_data, synthetic_data)\n",
    "                else:\n",
    "                    combined_client_data[client] = current_client_data\n",
    "\n",
    "        client_models = []\n",
    "        for client in combined_client_data:\n",
    "            client_model, avg_loss, accuracy = train_client(combined_client_data[client], global_model, criterion, epoch)\n",
    "            client_models.append(client_model.state_dict())\n",
    "\n",
    "        global_weights = average_weights(client_models)\n",
    "        global_model.load_state_dict(global_weights)\n",
    "        \n",
    "        # TODO: client_data_test needs slicing\n",
    "        test_accuracy = test_client(client_data_test, global_model)\n",
    "        accuracy_matrix.append(test_accuracy)\n",
    "        print(f\"Iteration: {ite} - Test Acc: {test_accuracy:.2f}%\")\n",
    "    return accuracy_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ea674df-9bee-4ae8-ba87-560aa79dc45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.37997332215309143\n",
      "1 0.1906331479549408\n",
      "2 0.18941910564899445\n",
      "3 0.1414875090122223\n",
      "4 0.0964934304356575\n",
      "5 0.11622291058301926\n",
      "6 0.1213747188448906\n",
      "7 0.07447434216737747\n",
      "8 0.07906822115182877\n",
      "9 0.07951866090297699\n",
      "10 0.12686841189861298\n",
      "11 0.07342164218425751\n",
      "12 0.06325269490480423\n",
      "13 0.06100992113351822\n",
      "14 0.06164216995239258\n",
      "15 0.06517747789621353\n",
      "16 0.05516740307211876\n",
      "17 0.08960085362195969\n",
      "18 0.043464548885822296\n",
      "19 0.06409883499145508\n",
      "20 0.05567973852157593\n",
      "21 0.036020535975694656\n",
      "22 0.03205642104148865\n",
      "23 0.05768542364239693\n",
      "24 0.031436700373888016\n",
      "25 0.0751633569598198\n",
      "26 0.03487636521458626\n",
      "27 0.05606229975819588\n",
      "28 0.045099012553691864\n",
      "29 0.03778448328375816\n",
      "30 0.052741117775440216\n",
      "31 0.024480756372213364\n",
      "32 0.04910240322351456\n",
      "33 0.07275908440351486\n",
      "34 0.030397837981581688\n",
      "35 0.0432523712515831\n",
      "36 0.0645844042301178\n",
      "37 0.03133029118180275\n",
      "38 0.035640913993120193\n",
      "39 0.038860175758600235\n",
      "40 0.041425671428442\n",
      "41 0.035326067358255386\n",
      "42 0.025066068395972252\n",
      "43 0.032289352267980576\n",
      "44 0.056027647107839584\n",
      "45 0.043293245136737823\n",
      "46 0.029170090332627296\n",
      "47 0.057680536061525345\n",
      "48 0.06843381375074387\n",
      "49 0.03220834955573082\n",
      "50 0.049901433289051056\n",
      "51 0.0569242499768734\n",
      "52 0.034032758325338364\n",
      "53 0.029181307181715965\n",
      "54 0.06897225230932236\n",
      "55 0.03764984756708145\n",
      "56 0.030357930809259415\n",
      "57 0.0270345751196146\n",
      "58 0.06923126429319382\n",
      "59 0.01884087361395359\n",
      "60 0.03750171884894371\n",
      "61 0.01820812188088894\n",
      "62 0.0395384319126606\n",
      "63 0.0257649514824152\n",
      "64 0.041727423667907715\n",
      "65 0.019321026280522346\n",
      "66 0.03918248042464256\n",
      "67 0.03127148374915123\n",
      "68 0.02089284174144268\n",
      "69 0.018481014296412468\n",
      "70 0.02583283558487892\n",
      "71 0.023913899436593056\n",
      "72 0.02517230622470379\n",
      "73 0.017680685967206955\n",
      "74 0.06491719186306\n",
      "75 0.028508221730589867\n",
      "76 0.03511647507548332\n",
      "77 0.024807048961520195\n",
      "78 0.024851566180586815\n",
      "79 0.01724294386804104\n",
      "80 0.035547275096178055\n",
      "81 0.02793424390256405\n",
      "82 0.036659516394138336\n",
      "83 0.021730637177824974\n",
      "84 0.01651911623775959\n",
      "85 0.012602165341377258\n",
      "86 0.03833940252661705\n",
      "87 0.015760017558932304\n",
      "88 0.030370092019438744\n",
      "89 0.01915634609758854\n",
      "90 0.04593893513083458\n",
      "91 0.0326077826321125\n",
      "92 0.016022054478526115\n",
      "93 0.015682941302657127\n",
      "94 0.033907562494277954\n",
      "95 0.020633790642023087\n",
      "96 0.045512448996305466\n",
      "97 0.015479186549782753\n",
      "98 0.020292935892939568\n",
      "99 0.021819690242409706\n",
      "100 0.03632354363799095\n",
      "101 0.041301384568214417\n",
      "102 0.021841196343302727\n",
      "103 0.03078659251332283\n",
      "104 0.024896813556551933\n",
      "105 0.030297845602035522\n",
      "106 0.03532637655735016\n",
      "107 0.04310140758752823\n",
      "108 0.034217651933431625\n",
      "109 0.024816198274493217\n",
      "110 0.04353995993733406\n",
      "111 0.03644479438662529\n",
      "112 0.04018516466021538\n",
      "113 0.031047245487570763\n",
      "114 0.0166416447609663\n",
      "115 0.029379306361079216\n",
      "116 0.01320156455039978\n",
      "117 0.04195909574627876\n",
      "118 0.030467022210359573\n",
      "119 0.03469004109501839\n",
      "120 0.012441460974514484\n",
      "121 0.04724077507853508\n",
      "122 0.029476607218384743\n",
      "123 0.026535457000136375\n",
      "124 0.047310978174209595\n",
      "125 0.02799222804605961\n",
      "126 0.015171500854194164\n",
      "127 0.017133820801973343\n",
      "128 0.041089266538619995\n",
      "129 0.013060969300568104\n",
      "130 0.01671392098069191\n",
      "131 0.030633149668574333\n",
      "132 0.017561284825205803\n",
      "133 0.018096189945936203\n",
      "134 0.02128983847796917\n",
      "135 0.024431675672531128\n",
      "136 0.03179022669792175\n",
      "137 0.0388573482632637\n",
      "138 0.027887124568223953\n",
      "139 0.03042774833738804\n",
      "140 0.04853946343064308\n",
      "141 0.024245738983154297\n",
      "142 0.0180436410009861\n",
      "143 0.01889738440513611\n",
      "144 0.013511818833649158\n",
      "145 0.018320759758353233\n",
      "146 0.03101813606917858\n",
      "147 0.021728569641709328\n",
      "148 0.010415734723210335\n",
      "149 0.025912925601005554\n",
      "150 0.020182328298687935\n",
      "151 0.03020606003701687\n",
      "152 0.024089530110359192\n",
      "153 0.0273300651460886\n",
      "154 0.025736767798662186\n",
      "155 0.016491446644067764\n",
      "156 0.013528076000511646\n",
      "157 0.009915786795318127\n",
      "158 0.03624146431684494\n",
      "159 0.012556755915284157\n",
      "160 0.014631937257945538\n",
      "161 0.04466148093342781\n",
      "162 0.011783885769546032\n",
      "163 0.026886049658060074\n",
      "164 0.018999256193637848\n",
      "165 0.039501700550317764\n",
      "166 0.011123249307274818\n",
      "167 0.036428339779376984\n",
      "168 0.008507792837917805\n",
      "169 0.0207317303866148\n",
      "170 0.01136303972452879\n",
      "171 0.016547173261642456\n",
      "172 0.012521946802735329\n",
      "173 0.03602040931582451\n",
      "174 0.021744878962635994\n",
      "175 0.02138667367398739\n",
      "176 0.047988757491111755\n",
      "177 0.025547776371240616\n",
      "178 0.011900867335498333\n",
      "179 0.029195860028266907\n",
      "180 0.014531570486724377\n",
      "181 0.03369681164622307\n",
      "182 0.011180862784385681\n",
      "183 0.04675444960594177\n",
      "184 0.035774942487478256\n",
      "185 0.02151823230087757\n",
      "186 0.021321073174476624\n",
      "187 0.0203904639929533\n",
      "188 0.017591556534171104\n",
      "189 0.015412268228828907\n",
      "190 0.029284287244081497\n",
      "191 0.019338542595505714\n",
      "192 0.016169635578989983\n",
      "193 0.020040040835738182\n",
      "194 0.027280379086732864\n",
      "195 0.019899455830454826\n",
      "196 0.016958778724074364\n",
      "197 0.016953468322753906\n",
      "198 0.03226443752646446\n",
      "199 0.009628812782466412\n"
     ]
    }
   ],
   "source": [
    "eps_model = UNet(image_channels=1, n_channels=32, ch_mults=[1, 2, 4], is_attn=[False, False, True]).to(device)\n",
    "diffusion_model = DenoiseDiffusion(eps_model=eps_model, n_steps=1000, device=device)\n",
    "diffusion_model = train_diffusion_model(copy.deepcopy(diffusion_model), client_data_train[0][(0 // 20) % 5])\n",
    "synthetic_data = generate_synthetic_data(diffusion_model, amount=100)\n",
    "\n",
    "# synthetic_data = torch.load('synthetic_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcfb7f1a-cbdb-48be-a0bc-12b4088dd370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = synthetic_data[0].cpu().numpy()\n",
    "image = image.squeeze()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Synthetic Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe579d-6630-4f34-855d-82d0f9e5544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "eps_model = UNet(image_channels=1, n_channels=32, ch_mults=[1, 2, 4], is_attn=[False, False, True])\n",
    "\n",
    "diffusion_models = {}\n",
    "for client_id in range(len(client_data_train)):\n",
    "    eps_model = eps_model.to(device)\n",
    "    diffusion_models[client_id] = DenoiseDiffusion(eps_model=eps_model, n_steps=100, device=device)\n",
    "\n",
    "# accuracy_matrix = FedAvg(model, client_data_train, client_data_test, iterations=1000, epoch=5)\n",
    "accuracy_matrix = FedAvg_with_Diffusion(model, client_data_train, client_data_test, diffusion_models, iterations=100, epoch=5)\n",
    "\n",
    "file_name = f'CFL_MNIST_Diffsion.npy'\n",
    "np.save(file_name, accuracy_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f404846-a48a-4cd7-8de3-72bd4c3ff02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b28b5-2524-4018-9ebb-ca92010e617d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5aa0a-5283-4382-9a30-381c769ab2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd6f62d-37ef-4c03-bc0f-25c02b57fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_memory_size(model):\n",
    "    param_size = 0\n",
    "    grad_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "        if param.grad is not None:\n",
    "            grad_size += param.grad.nelement() * param.grad.element_size()\n",
    "    total_size = param_size + grad_size\n",
    "    print(total_size / (1024 * 1024))\n",
    "\n",
    "eps_model = UNet(image_channels=1, n_channels=32, ch_mults=[1, 2, 4], is_attn=[False, False, True])\n",
    "model_memory_size(eps_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
